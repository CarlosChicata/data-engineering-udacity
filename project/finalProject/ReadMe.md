# Capstone : Basic Analytics workflow for delivery shipment startup
----------
## Context

The "Envialo!" is a peruvian startup is dedicated to delivery shipment between clients (company-users type). They are 3 year in production and have 3 branch in Perú (arequipa, lima and cuzco). They need to improve their process and recently create a analytics team. They wants to be the most important startup in this area in Perú.

You are newly hired in a delivery shipments startup like data engineering!. You open this area in your work and you have any task from analytics team to improve their jobs.

The analytics team work using manual processes to generate reports about performance of roadmaps, agents and company in different time ranges and branches; they separate bad data from good data to generate reports using specified requirements. In case of bad data, analytics team must need to analyze it later but now they need to storage in specified JSON format.

## General Purpose
You will create two things:
 1. A data warehouse to manage reports of analytics team.
 2. a data lake will store a bad datas.

## Specified Objects and requirements
the following sections explain more details about how you need to implement this tasks:

## Reports
The analytics team need following reports:

1. **Roadmap Report**: Ver como fue el rendimiento de las rutas durante este mes.
2. **Agent Report**: Check performance of agents affiliated their.
4. **Top delivery Report**: Saber cuales compañias envian mas pedidos por un mes consultado.

## Bad data
The format of bad datas is:

## Notes about the project

* The data is generated for this project; so they are faked. they do not belong to any company or public domain.

-----------

-----------
## Tasks of project

## Models of datawarehouse


## Diagram of arquitecture of project


## Set up of platform


## How to run this project

